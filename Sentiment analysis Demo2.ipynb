{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sentiment analysis Demo2.ipynb","provenance":[],"mount_file_id":"1DACbcTwMYcHMXkp84gSao8WL5t6rYRqY","authorship_tag":"ABX9TyMwWPgLET5aJhoPlYKkog1f"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"SC8cuqOWARkq","colab_type":"code","outputId":"887a0be7-f983-4f06-d425-1d1b07594f02","executionInfo":{"status":"ok","timestamp":1588756611477,"user_tz":-330,"elapsed":4738,"user":{"displayName":"Arkadip Maitra","photoUrl":"","userId":"02777426125105772731"}},"colab":{"base_uri":"https://localhost:8080/","height":110}},"source":["!pip install GetOldTweets3"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: GetOldTweets3 in /usr/local/lib/python3.6/dist-packages (0.0.11)\n","Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (4.2.6)\n","Requirement already satisfied: pyquery>=1.2.10 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (1.4.1)\n","Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.6/dist-packages (from pyquery>=1.2.10->GetOldTweets3) (1.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sW80OPaOAk-g","colab_type":"code","colab":{}},"source":["import GetOldTweets3 as got\n","import string\n","from collections import Counter\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I5ii3lWQAufo","colab_type":"code","colab":{}},"source":["def get_tweets():\n","  tweetCriteria = got.manager.TweetCriteria().setQuerySearch('elon musk')\\\n","                                           .setSince(\"2018-01-01\")\\\n","                                           .setUntil(\"2020-01-01\")\\\n","                                           .setMaxTweets(1000)\n","  tweets = got.manager.TweetManager.getTweets(tweetCriteria) #List of objects stored in tweets variable\n","  text_tweets = [[tweet.text] for tweet in tweets] #iterating through tweets variable and storing it in text_tweets \n","  return text_tweets"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FAZwTg4gHmcr","colab_type":"code","colab":{}},"source":["text_tweets = get_tweets()\n","text = \"\"\n","\n","for i in range(0, len(text_tweets)):\n","  text = text_tweets[i][0] + \" \" + text\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"01ZlvQGGI9ic","colab_type":"code","colab":{}},"source":["lower_case = text.lower()\n","clean_text = lower_case.translate(str.maketrans('', '', string.punctuation))\n","tokenized_words = clean_text.split()\n","\n","stop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n","              \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\",\n","              \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\",\n","              \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\",\n","              \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\",\n","              \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\",\n","              \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\",\n","              \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\",\n","              \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\n","              \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n","\n","final_words = []\n","for word in tokenized_words:\n","  if word not in stop_words:\n","    final_words.append(word)\n","\n","emotion_list = []\n","with open('/content/drive/My Drive/emotion1.txt', 'r') as file:\n","  for line in file:\n","    clear_line = line.replace('\\n', '').replace(',', '').replace(\"'\", '').strip()\n","    word, emotion = clear_line.split(':')\n","    if word in final_words:\n","      emotion_list.append(emotion)\n","\n","w = Counter(emotion_list)\n","\n","fig, axs = plt.subplots()\n","axs.bar(w.keys(), w.values())\n","fig.autofmt_xdate()\n","plt.savefig('graph1.png')\n","plt.show()"],"execution_count":0,"outputs":[]}]}